# 模型评估指标选择

由于数据分布严重偏态，并且本文目的在于判断可能会购买的高质量客户，因此“将可能购买的用户识别为可能不购买”和将“可能不购买的用户识别为可能购买”这两个错误的严重程度是不一样的。仅仅使用准确率作为模型评估指标有失偏颇，因此本文加入了f1值作为模型准确率的参考。

而在模型的训练集、测试集比例选择方面，由于该数据集在清洗后仍有1e5的数量级，属于大型数据集，为保证训练结果的普适性，设置训练集与测试集比例为9：1。

# 模型选择

模型融合是机器学习中的常用算法之一，主要分为硬投票和软投票两个大类，向下细分则有stacking、averaging、bagging、boosting、stacking五类。

本文使用stacking方法进行模型融合。其主要思想是训练一个二级模型，并对多个一级模型的预测结果结果进行总结，以填补各个一级模型的缺点，获得更高的准确率。由于一般意义上的Stacking在训练时存在容易过拟合的缺点，因此在一级模型训练时采用3折交叉验证。

（放图）

## 第一层分类器

### 一分类

由于数据过于倾斜，故将用户尝试使用一分类模型进行异常值检测。

```
type : OneClassSVM
train_size : 0.1
test_size : 0.9
--------------------------------------------------
AUC : NULL
ACC_value : 0.96584
Recall_value : 0.0
F1_Score_value : 0.0
Precesion_value : 0.0
ConfusionMatrix :
[[117489      5]
 [  4150      0]]
--------------------------------------------------
Report :
              precision    recall  f1-score   support

           0       0.97      1.00      0.98    117494
           1       0.00      0.00      0.00      4150

    accuracy                           0.97    121644
   macro avg       0.48      0.50      0.49    121644
weighted avg       0.93      0.97      0.95    121644
```

可以看出各维度评价值都很低，且该模型预测时间极长，综上此异常值检测模型不适用该场景。

### 二分类

在数据预处理部分，因为长尾数据维度比例很高，且难以有效区别数据中的噪音和特殊值，如果盲目对其进行标准化，并使用线性模型进行分类，可能不会收到较好的准确值。以逻辑回归为例，初步训练模型结果如下。

```
==================================================
type : LR
--------------------------------------------------
AUC : NULL
ACC_value : 0.65130
Recall_value : 0.89438
F1_Score_value : 0.14449
Precesion_value : 0.07859
ConfusionMatrix :
[[8405 4666]
 [  47  398]]
--------------------------------------------------
Report :
              precision    recall  f1-score   support

           0       0.99      0.64      0.78     13071
           1       0.08      0.89      0.14       445

    accuracy                           0.65     13516
   macro avg       0.54      0.77      0.46     13516
weighted avg       0.96      0.65      0.76     13516

==================================================
```

可以看出，虽然逻辑回归召回率高但准确率极低，属于“广撒网， 多敛鱼”的策略，并不符合“小成本促销”的核心思想，因此不采用该模型。

若使用基于决策树的模型进行预测。初始选择XGBoost、RandomForest、DicisionTree作为备选模型。为了粗浅的比较各模型的效果，初步训练各模型结果如下。

```
type : XGBoost
train_size : 0.9
test_size : 0.1
sampling_strategy : 0.05
num_boost_round : 7
booster : gbtree
objective : binary:logistic
eval_metric : auc
max_depth : 5
eta : 0.005
seed : 0
--------------------------------------------------
AUC : NULL
ACC_value : 0.98239
Recall_value : 0.64682
F1_Score_value : 0.73258
Precesion_value : 0.84455
ConfusionMatrix :
[[12952    60]
 [  178   326]]
--------------------------------------------------
Report :
              precision    recall  f1-score   support

           0       0.99      1.00      0.99     13012
           1       0.84      0.65      0.73       504

    accuracy                           0.98     13516
   macro avg       0.92      0.82      0.86     13516
weighted avg       0.98      0.98      0.98     13516

==================================================
```

```
==================================================
type : Tree
max_depth : 9
train_size : 0.9
test_size : 0.1
--------------------------------------------------
AUC : NULL
ACC_value : 0.98453
Recall_value : 0.68161
F1_Score_value : 0.74236
Precesion_value : 0.81501
ConfusionMatrix :
[[13128    69]
 [  142   304]]
--------------------------------------------------
Report :
              precision    recall  f1-score   support

           0       0.99      0.99      0.99     13197
           1       0.82      0.68      0.74       446

    accuracy                           0.98     13643
   macro avg       0.90      0.84      0.87     13643
weighted avg       0.98      0.98      0.98     13643

==================================================
```

```
==================================================
type : RandomForest
train_size : 0.9
test_size : 0.1
--------------------------------------------------
AUC : NULL
ACC_value : 0.97602
Recall_value : 0.26590
F1_Score_value : 0.41935
Precesion_value : 0.99152
ConfusionMatrix :
[[13075     1]
 [  323   117]]
--------------------------------------------------
Report :
              precision    recall  f1-score   support

           0       0.98      1.00      0.99     13076
           1       0.99      0.27      0.42       440

    accuracy                           0.98     13516
   macro avg       0.98      0.63      0.70     13516
weighted avg       0.98      0.98      0.97     13516

==================================================
```

可以看出，随机森林准确率高，但召回率略低。XGBoost在准确率和召回率方面均较优秀，普通的决策树两指标均低，在三个模型中分类效果垫底，因此采用该模型。

## 第二层模型

第一层模型预测后，需要一个总结性较好的模型进行融合，由于第一层模型结果都较为优秀，因此可以直接使用线性模型对预测结果总结以得出最终结果，通过阅读文献可知第二层常用模型为逻辑回归。



# 模型调参

在确定模型后需要对模型进行超参数调整以提升模型准确率。本文采用随机搜索调参粗校，手动调参精校的方式对模型进行修整。

随机搜索是目前常用的超参数优化算法，具有随机性，快速性的特点。该算法基于网格搜索，即每轮计算中选取的超参数数量固定。当超参数数量较大时，搜索时间将成指数级增长，非常耗时。
随机搜索在每一轮优化中，随机选取不定量的超参数，经过若干轮计算后一定能找到最优的超参数组合。当存在大量超参数待优化时，其效率较高。

调参完成后各模型训练结果如下

```
AUC_value : 0.98292
ACC_value : 0.99010
Precesion_value : 0.88199
ConfusionMatrix :
[[131279    508]
 [   842   3797]]
--------------------------------------------------
Report :
              precision    recall  f1-score   support

           0       0.99      1.00      0.99    131787
           1       0.88      0.82      0.85      4639

    accuracy                           0.99    136426
   macro avg       0.94      0.91      0.92    136426
weighted avg       0.99      0.99      0.99    136426
```

```
==================================================
type : RandomForest
train_size : 0.9
test_size : 0.1
--------------------------------------------------
AUC : NULL
ACC_value : 0.97980
Recall_value : 0.42231
F1_Score_value : 0.58573
Precesion_value : 0.95544
ConfusionMatrix :
[[13050     9]
 [  264   193]]
--------------------------------------------------
Report :
              precision    recall  f1-score   support

           0       0.98      1.00      0.99     13059
           1       0.96      0.42      0.59       457

    accuracy                           0.98     13516
   macro avg       0.97      0.71      0.79     13516
weighted avg       0.98      0.98      0.98     13516

==================================================
```

```
XGBoost
ACC_value : 0.98697
Recall_value : 0.74610
F1_Score_value : 0.79196
Precesion_value : 0.84382
ConfusionMatrix :
[[13005    62]
 [  114   335]]
--------------------------------------------------
Report :
              precision    recall  f1-score   support

           0       0.99      1.00      0.99     13067
           1       0.84      0.75      0.79       449

    accuracy                           0.99     13516
   macro avg       0.92      0.87      0.89     13516
weighted avg       0.99      0.99      0.99     13516

==================================================
```

# 模型效果分析与解释

在模型解释方面，本文使用Python的SHAP库进行分析。

SHAP是基于博弈论的为所有机器学习、深度学习提供一个解释的方案的库，能评价树模型中的维度特征对于结果的贡献度。与特征重要性相比，SHAP value不仅能反映出每一个样本内，各个维度特征的影响力，而且还表现出影响的正负性，是当前主流的机器学习模型最佳解释工具

使用SHAP对逻辑回归模型进行分析，可以发现XGBoost和随机森林都对最终结果产生了贡献，其中第一层各模型结果对最终结果影响比例和总体呈现如下：

（图）

由于逻辑森林准确率高，即该模型判断为购买的用户几乎都购买了产品，结合图片可以发现随机森林模型中对这些用户的判断，在融合模型中的影响因子也很高。其他未识别出来的用户也离判别点很近，经过XGBoost模型贡献后也能精准补盲。
